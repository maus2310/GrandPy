{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Loading data and working with grandPy objects\n",
    "\n",
    "<span style=\"color:green\">Notiz: alles was rot ist, ist noch nicht umgesetzt oder müsste noch überarbeitet werden durch Links etc.</span>\n",
    "\n",
    "GrandPy is a Python package for the analysis of RNA-seq experiments involving metabolic RNA labeling with nucleotide conversion, such as SLAM-seq experiments <span style=\"color:red\">[https://www.nature.com/articles/nmeth.4435]</span>. In such experiments, nucleoside analogs such as 4sU are added to living cells, which take it up and incorporate it into newly synthesized RNA. Before sequencing, 4sU is converted into a cytosin analog. Reads covering 4sU sites therefore have characteristic T-to-C mismatches after read mapping, in principle providing the opportunity to differentiate newly synthesized (during the time of labeling) from preexisting RNA.\n",
    "\n",
    "Confounders such as sequencing errors or read that originate from newly synthesized RNA but, by chance, do not cover sites of 4sU incorporation (usually 20-80% of all \"new read\") can be handled using specialized methods such as GRAND-SLAM <span style=\"color:red\">[https://academic.oup.com/bioinformatics/article/34/13/i218/5045735?login=true]</span>.\n",
    "\n",
    "# Reading in the data\n",
    "\n",
    "Throughout this vignette, we will be using the GRAND-SLAM processed SLAM-seq data set from Finkel et al.2021 <span style=\"color:red\">[https://academic.oup.com/bioinformatics/article/34/13/i218/5045735]</span>. The data set contains time series (progressive labeling) samples from a human epithelial cell line (Calu3 cells); half of the samples were infected with SARS-CoV-2 for different periods of time.\n",
    "\n",
    "The output of GRAND-SLAM is a tsv file where rows are genes and columns are read counts and other statistics (e.g., the new-to-total RNA ratio) for all samples. The data set is available on zenodo (\"https://zenodo.org/record/5834034/files/sars.tsv.gz\"). We start by reading this file into Python:"
   ],
   "id": "52df091142cc2d28"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T11:22:52.141124Z",
     "start_time": "2025-06-20T11:22:49.342974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Package installation\n",
    "from Py.load import *\n",
    "sars = read_grand(\"../data/sars.tsv\", design=(\"Condition\", \"Time\", \"Replicate\"))\n",
    "print(sars.columns)"
   ],
   "id": "ce3f00b85976da6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected dense format -> using dense reader\n",
      "['Mock.no4sU.A', 'Mock.1h.A', 'Mock.2h.A', 'Mock.2h.B', 'Mock.3h.A', 'Mock.4h.A', 'SARS.no4sU.A', 'SARS.1h.A', 'SARS.2h.A', 'SARS.2h.B', 'SARS.3h.A', 'SARS.4h.A']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kathi\\PycharmProjects\\grandpy\\Py\\utils.py:61: UserWarning: Duplicate gene symbols found: STPG4, PDE11A, TXNRD3NB, ARL14EPL, HIST1H3D, SOGA3, MATR3, RABGEF1, POLR2J2, KBTBD11-OT1; they have been renamed to ensure uniqueness (e.g., MATR3 → MATR3_1).\n",
      "  warnings.warn(f\"Duplicate gene symbols found: {', '.join(duplicates_list)}; they have been renamed to ensure uniqueness (e.g., MATR3 → MATR3_1).\")\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "When reading in the file, we have to define the ``design`` vector. This is used to infer metadata automatically from sample names. Here sample names consist of three parts separated by dots as shown above (the Columns function returns the sample names or cell ids when analyzing a single cell data set). Each part in the sample name represents an aspect of the design. For example, the sample named Mock.2h.A is a sample from the mock condition (i.e. not infected by SARS-CoV-2), subjected to metabolic labeling for 2 hours, and is the first replicate (i.e. replicate \"A\"). This sample name is consistent with the three element design vector used above. It is possible to specify other design elements (of course the samples would have to be named accordingly). A list of reasonable options is predefined in the dictionary `DESIGN_KEYS`.\n",
    "\n",
    "There are names (i.e. the things you specify in the design vector) that have additional semantics. For example, for the name `duration.4sU`the values are interpreted like this: 4h is converted into the number 4, 30min into 0.5, and no4sU into <span style=\"color:red\">0 (bei uns gerade NaN)</span>. For more information, see <span style=\"color:red\">below</span>. The design vector is mandatory. Attempting to read in the data without it results in an error:"
   ],
   "id": "2b9995e1b21a3782"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T11:22:54.715067Z",
     "start_time": "2025-06-20T11:22:52.719890Z"
    }
   },
   "cell_type": "code",
   "source": "sars_wrong = read_grand(\"../data/sars.tsv\") # Fehlermeldung könnte man noch verkürzen, gerade schon dolle lang",
   "id": "bc7af08f0cc34232",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected dense format -> using dense reader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kathi\\PycharmProjects\\grandpy\\Py\\utils.py:61: UserWarning: Duplicate gene symbols found: STPG4, PDE11A, TXNRD3NB, ARL14EPL, HIST1H3D, SOGA3, MATR3, RABGEF1, POLR2J2, KBTBD11-OT1; they have been renamed to ensure uniqueness (e.g., MATR3 → MATR3_1).\n",
      "  warnings.warn(f\"Duplicate gene symbols found: {', '.join(duplicates_list)}; they have been renamed to ensure uniqueness (e.g., MATR3 → MATR3_1).\")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Design must be  explicitly provided.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\grandpy\\Py\\load.py:268\u001B[39m, in \u001B[36mbuild_coldata\u001B[39m\u001B[34m(names, design)\u001B[39m\n\u001B[32m    267\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m design \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m268\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mDesign must be  explicitly provided.\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    269\u001B[39m \u001B[38;5;66;03m# predefined = list(DESIGN_KEYS.values())\u001B[39;00m\n\u001B[32m    270\u001B[39m \u001B[38;5;66;03m# design = tuple(predefined[i] if i < len(predefined) else f\"Design_{i+1}\" for i in range(max_fields))\u001B[39;00m\n",
      "\u001B[31mValueError\u001B[39m: Design must be  explicitly provided.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m sars_wrong = \u001B[43mread_grand\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m../data/sars.tsv\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m# Fehlermeldung könnte man noch verkürzen, gerade schon dolle lang\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\grandpy\\Py\\load.py:640\u001B[39m, in \u001B[36mread_grand\u001B[39m\u001B[34m(prefix, pseudobulk, targets, **kwargs)\u001B[39m\n\u001B[32m    638\u001B[39m file_path = resolve_prefix_path(prefix, pseudobulk=pseudobulk, targets=targets)\n\u001B[32m    639\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mDetected dense format -> using dense reader\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m640\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mread_dense\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mfile_path\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\grandpy\\Py\\load.py:564\u001B[39m, in \u001B[36mread_dense\u001B[39m\u001B[34m(file_path, default_slot, design, classification_genes, classification_genes_label, classify_genes_func)\u001B[39m\n\u001B[32m    534\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mread_dense\u001B[39m(file_path, default_slot=\u001B[33m\"\u001B[39m\u001B[33mcount\u001B[39m\u001B[33m\"\u001B[39m, design=\u001B[38;5;28;01mNone\u001B[39;00m, *, classification_genes=\u001B[38;5;28;01mNone\u001B[39;00m, classification_genes_label=\u001B[33m\"\u001B[39m\u001B[33mViral\u001B[39m\u001B[33m\"\u001B[39m, classify_genes_func=\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m    535\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    536\u001B[39m \u001B[33;03m    Reads a GRAND-SLAM TSV file as dense (NumPy) matrices and returns a GrandPy object.\u001B[39;00m\n\u001B[32m    537\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    561\u001B[39m \u001B[33;03m        A GrandPy object populated with dense matrices and metadata.\u001B[39;00m\n\u001B[32m    562\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m564\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msparse\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdefault_slot\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdefault_slot\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdesign\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdesign\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    565\u001B[39m \u001B[43m                 \u001B[49m\u001B[43mclassification_genes\u001B[49m\u001B[43m=\u001B[49m\u001B[43mclassification_genes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclassification_genes_label\u001B[49m\u001B[43m=\u001B[49m\u001B[43mclassification_genes_label\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    566\u001B[39m \u001B[43m                 \u001B[49m\u001B[43mclassify_genes_func\u001B[49m\u001B[43m=\u001B[49m\u001B[43mclassify_genes_func\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\grandpy\\Py\\load.py:752\u001B[39m, in \u001B[36m_read\u001B[39m\u001B[34m(file_path, sparse, default_slot, design, classification_genes, classification_genes_label, classify_genes_func, pseudobulk, targets)\u001B[39m\n\u001B[32m    749\u001B[39m     classify_genes_func = \u001B[38;5;28;01mlambda\u001B[39;00m gene_info: classify_genes(gene_info, custom_classes=custom, use_default=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m    751\u001B[39m gene_info = build_gene_info(df, classify_genes_func)\n\u001B[32m--> \u001B[39m\u001B[32m752\u001B[39m coldata = \u001B[43mbuild_coldata\u001B[49m\u001B[43m(\u001B[49m\u001B[43msample_names\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdesign\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    753\u001B[39m slots = pad_slots(slots, sparse, coldata, slot_sample_names)\n\u001B[32m    755\u001B[39m metadata = {\n\u001B[32m    756\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mDescription\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33m\"\u001B[39m\u001B[33mLoaded via read_grand() (TSV)\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    757\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mdefault_slot\u001B[39m\u001B[33m\"\u001B[39m: default_slot,\n\u001B[32m   (...)\u001B[39m\u001B[32m    761\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mtargets\u001B[39m\u001B[33m\"\u001B[39m: targets\n\u001B[32m    762\u001B[39m }\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\grandpy\\Py\\load.py:274\u001B[39m, in \u001B[36mbuild_coldata\u001B[39m\u001B[34m(names, design)\u001B[39m\n\u001B[32m    272\u001B[39m         design += \u001B[38;5;28mtuple\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mExtra_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m\u001B[32m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(max_fields - \u001B[38;5;28mlen\u001B[39m(design)))\n\u001B[32m    273\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m274\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mDesign must be  explicitly provided.\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    277\u001B[39m design = design[:max_fields]\n\u001B[32m    279\u001B[39m aligned_rows = [parts + [\u001B[38;5;28;01mNone\u001B[39;00m] * (max_fields - \u001B[38;5;28mlen\u001B[39m(parts)) \u001B[38;5;28;01mfor\u001B[39;00m parts \u001B[38;5;129;01min\u001B[39;00m split_names]\n",
      "\u001B[31mValueError\u001B[39m: Design must be  explicitly provided."
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Alternatively, a table containing the metadata can be specified. Make sure that it contains a `Name` column matching the names in the GRAND-SLAM output table:",
   "id": "6d8012805e46d830"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T11:28:00.953905Z",
     "start_time": "2025-06-20T11:27:59.886514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "name = [\"Mock.no4sU.A\", \"Mock.1h.A\", \"Mock.2h.A\", \"Mock.2h.B\", \"Mock.3h.A\", \"Mock.4h.A\", \"SARS.no4sU.A\", \"SARS.1h.A\", \"SARS.2h.A\", \"SARS.2h.B\", \"SARS.3h.A\", \"SARS.4h.A\"]\n",
    "\n",
    "conditions = [\"Mock\"] * 6 + [\"SARS\"] * 6\n",
    "\n",
    "design_df = pd.DataFrame({\"Name\": name,\n",
    "                          \"Condition\": conditions})\n",
    "\n",
    "sars_meta = read_grand(\"../data/sars.tsv\", design = design_df)"
   ],
   "id": "7e52409fff9b9aee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected dense format -> using dense reader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kathi\\PycharmProjects\\grandpy\\Py\\utils.py:61: UserWarning: Duplicate gene symbols found: STPG4, PDE11A, TXNRD3NB, ARL14EPL, HIST1H3D, SOGA3, MATR3, RABGEF1, POLR2J2, KBTBD11-OT1; they have been renamed to ensure uniqueness (e.g., MATR3 → MATR3_1).\n",
      "  warnings.warn(f\"Duplicate gene symbols found: {', '.join(duplicates_list)}; they have been renamed to ensure uniqueness (e.g., MATR3 → MATR3_1).\")\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# What is the grandPy object\n",
    "\n",
    "`read_grand` returns a grandPy object, which contains\n",
    "\n",
    "1. metadata for genes\n",
    "2. metadata for samples/cells (as inferred from the sample names by the design parameter)\n",
    "3. all data matrices (counts, normalized counts, ntrs, etc. these types of data are called \"slots\")\n",
    "4. analysis results\n",
    "\n",
    "Metadata (1. and 2.) are described below. How to work with the data matrices and analysis results is described in a separate <span style=\"color:red\">vignette [Working with data matrices and analysis results]</span>.\n",
    "\n",
    "# Working with grandPy objects\n",
    "\n",
    "Here we will see how to work with grandPy objects in general. A short summary can be displayed when `print`ing the object, and there are several functinos to retrieve general information about the object:"
   ],
   "id": "898d70860c82c871"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T11:33:53.719991Z",
     "start_time": "2025-06-20T11:33:53.706642Z"
    }
   },
   "cell_type": "code",
   "source": "print(sars) # Link fehlt",
   "id": "868a9077ac36ab95",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GrandPy:\n",
      "Read from sars\n",
      "19659 genes, 12 samples/cells\n",
      "Available data slots: ['count', 'ntr', 'alpha', 'beta']\n",
      "Available analyses: []\n",
      "Available plots: {}\n",
      "Default data slot: count\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T11:34:09.510862Z",
     "start_time": "2025-06-20T11:34:09.471936Z"
    }
   },
   "cell_type": "code",
   "source": "print(sars.title)",
   "id": "cbdc3f0edab03e52",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sars\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T11:34:48.825852Z",
     "start_time": "2025-06-20T11:34:48.810140Z"
    }
   },
   "cell_type": "code",
   "source": "print(len(sars.genes)) # so?",
   "id": "3d3886922a51a5be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19659\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T11:35:04.176926Z",
     "start_time": "2025-06-20T11:35:04.157945Z"
    }
   },
   "cell_type": "code",
   "source": "print(len(sars.coldata)) # so?",
   "id": "443d3ee445a9d8a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "It is straight-forward to filter genes:",
   "id": "20c9e3e4ad8443d8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T11:36:38.258135Z",
     "start_time": "2025-06-20T11:36:38.250728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# sars = sars.filter_genes # fehlt bei processing.py\n",
    "# print(len(sars.genes))"
   ],
   "id": "247da2955b9c3e14",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "By default genes are retained if they have 100 read counts in at least half of the samples (or cells). There are many options how to filter by genes (note that `filter_genes` returns a new grandPy object, and below we directly call `len()` on this new object to check how many genes are retained by filtering):",
   "id": "2956390d4b69d53a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T11:42:52.057792Z",
     "start_time": "2025-06-20T11:42:52.044344Z"
    }
   },
   "cell_type": "code",
   "source": "# print(\"Genes with at least 1000 read counts in half of the columns: \\n\", len(sars.genes)) # filter_genes fehlt bei processing.py",
   "id": "2ca2127594f21a4e",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T11:44:20.262505Z",
     "start_time": "2025-06-20T11:44:20.253181Z"
    }
   },
   "cell_type": "code",
   "source": "# print(\"Genes with at least 1000 read counts in half of the columns (retain two genes that are otherwise filtered): \\n\", ) # filter_genes fehlt bei processing.py",
   "id": "5b961114b3c883d4",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T11:45:11.782120Z",
     "start_time": "2025-06-20T11:45:11.771621Z"
    }
   },
   "cell_type": "code",
   "source": "# print(\"Keep only these two genes: \\n\", ...) # filter_genes fehlt bei processing.py",
   "id": "c3fd30fb01e7e6c",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T11:46:38.136889Z",
     "start_time": "2025-06-20T11:46:38.129399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# sars = sars.normalizeTPM # normalizeTPM() fehlt bei processing.py\n",
    "# print(\"Genes with at least 10 TPM in half of the columns: \\n\", ...)"
   ],
   "id": "9f63268ac360d0c4",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "`filter_genes()` essentially removes rows from the data slots. It is also possible to remove columns (i.e. samples or cells). This is done using the subset function:",
   "id": "749285f3714131ec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T11:49:36.870868Z",
     "start_time": "2025-06-20T11:49:36.809353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mock = sars[:, sars.coldata[\"Condition\"] == \"Mock\"]\n",
    "print(mock) # filter_genes() fehlt noch, daher genes Anzhal noch falsch aber samples/cells richtig"
   ],
   "id": "1a3bd6c206bf4b9c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GrandPy:\n",
      "Read from sars\n",
      "19659 genes, 6 samples/cells\n",
      "Available data slots: ['count', 'ntr', 'alpha', 'beta']\n",
      "Available analyses: []\n",
      "Available plots: {}\n",
      "Default data slot: count\n",
      "\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The new grandPy object now only has 6 columns. The `columns`parameter to subset must be a logical vector, and you can use the names of the column metadata table (see below) as variables (i.e. the parameter here is a logical vector with all samples being TRUE where the `Condition`column is equal to \"Mock\".\n",
    "\n",
    "A closely related function is `split`, which returns a list of several grandPy objects, each composed of samples having the same `Condition`."
   ],
   "id": "fa0b3b984127293b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T11:55:43.127642Z",
     "start_time": "2025-06-20T11:55:43.099668Z"
    }
   },
   "cell_type": "code",
   "source": "# .split() fehlt in grandpy.py",
   "id": "46ea376976435f49",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T11:57:35.829988Z",
     "start_time": "2025-06-20T11:57:35.821067Z"
    }
   },
   "cell_type": "code",
   "source": "# lapply - funktion raussuchen in python",
   "id": "80f6bf6d81e03ef9",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The inverse of `split` is merge:",
   "id": "4ba5e07762570b05"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3544a037a12253d9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
