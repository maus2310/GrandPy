{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Loading data and working with grandPy objects\n",
    "\n",
    "<span style=\"color:green\">Notiz: alles was rot ist, ist noch nicht umgesetzt oder müsste noch überarbeitet werden durch Links etc.</span>\n",
    "\n",
    "GrandPy is a Python package for the analysis of RNA-seq experiments involving metabolic RNA labeling with nucleotide conversion, such as SLAM-seq experiments [[1]](https://www.nature.com/articles/nmeth.4435). In such experiments, nucleoside analogs such as 4sU are added to living cells, which take it up and incorporate it into newly synthesized RNA. Before sequencing, 4sU is converted into a cytosin analog. Reads covering 4sU sites therefore have characteristic T-to-C mismatches after read mapping, in principle providing the opportunity to differentiate newly synthesized (during the time of labeling) from preexisting RNA.\n",
    "\n",
    "Confounders such as sequencing errors or read that originate from newly synthesized RNA but, by chance, do not cover sites of 4sU incorporation (usually 20-80% of all \"new read\") can be handled using specialized methods such as GRAND-SLAM [[2]](https://academic.oup.com/bioinformatics/article/34/13/i218/5045735?login=true).\n",
    "\n",
    "# Reading in the data\n",
    "\n",
    "Throughout this vignette, we will be using the GRAND-SLAM processed SLAM-seq data set from Finkel et al.2021 [[3]](https://www.nature.com/articles/s41586-021-03610-3). The data set contains time series (progressive labeling) samples from a human epithelial cell line (Calu3 cells); half of the samples were infected with SARS-CoV-2 for different periods of time.\n",
    "\n",
    "The output of GRAND-SLAM is a tsv file where rows are genes and columns are read counts and other statistics (e.g., the new-to-total RNA ratio) for all samples. The data set is available on zenodo (\"https://zenodo.org/record/5834034/files/sars.tsv.gz\"). We start by reading this file into Python:"
   ],
   "id": "bc89f296d18b0dd3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Package installation\n",
    "from Py.load import *\n",
    "sars = read_grand(\"https://zenodo.org/record/5834034/files/sars.tsv.gz\", design=(\"Condition\", \"dur.4sU\", \"Replicate\"))\n",
    "print(sars.columns)"
   ],
   "id": "3446b6f063316e9b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "When reading in the file, we have to define the `design` vector. This is used to infer metadata automatically from sample names. Here sample names consist of three parts separated by dots as shown above (the Columns function returns the sample names or cell ids when analyzing a single cell data set). Each part in the sample name represents an aspect of the design. For example, the sample named Mock.2h.A is a sample from the mock condition (i.e. not infected by SARS-CoV-2), subjected to metabolic labeling for 2 hours, and is the first replicate (i.e. replicate \"A\"). This sample name is consistent with the three element design vector used above. It is possible to specify other design elements (of course the samples would have to be named accordingly). A list of reasonable options is predefined in the dictionary `DESIGN_KEYS`.\n",
    "\n",
    "There are names (i.e. the things you specify in the design vector) that have additional semantics. For example, for the name `duration.4sU` the values are interpreted like this: 4h is converted into the number 4, 30min into 0.5, and no4sU into 0. For more information, see Paragraph *Column Metadata*). The design vector is mandatory. Attempting to read in the data without it results in an error:"
   ],
   "id": "43619eb785f89c03"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "sars_wrong = read_grand(\"https://zenodo.org/record/5834034/files/sars.tsv.gz\")",
   "id": "98cfc59a38602a61"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Alternatively, a table containing the metadata can be specified. Make sure that it contains a `Name` column matching the names in the GRAND-SLAM output table:",
   "id": "a92f08d5b341b276"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "metadata = pd.DataFrame({\n",
    "    \"Name\": [\n",
    "        \"Mock.no4sU.A\",\"Mock.1h.A\",\"Mock.2h.A\",\"Mock.2h.B\",\n",
    "        \"Mock.3h.A\",\"Mock.4h.A\",\"SARS.no4sU.A\",\"SARS.1h.A\",\n",
    "        \"SARS.2h.A\",\"SARS.2h.B\",\"SARS.3h.A\",\"SARS.4h.A\"\n",
    "    ],\n",
    "    \"Condition\": [\"Mock\"] * 6 + [\"SARS\"] * 6\n",
    "})\n",
    "\n",
    "sars_meta = read_grand(\"../data/sars.tsv\", design=metadata)\n",
    "print(sars_meta)\n",
    "\n",
    "#TODO: Warning??"
   ],
   "id": "9c8673c446106d7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# What is the grandPy object\n",
    "\n",
    "`read_grand` returns a grandPy object, which contains\n",
    "\n",
    "1. metadata for genes\n",
    "2. metadata for samples/cells (as inferred from the sample names by the design parameter)\n",
    "3. all data matrices (counts, normalized counts, ntrs, etc. these types of data are called \"slots\")\n",
    "4. analysis results\n",
    "\n",
    "Metadata (1. and 2.) are described below. How to work with the data matrices and analysis results is described in a separate [vignette](vignette_04_working_with_data_matrices_and_analysis_results.ipynb).\n",
    "\n",
    "# Working with grandPy objects\n",
    "\n",
    "Here we will see how to work with grandPy objects in general. A short summary can be displayed when `print`ing the object, and there are several functions to retrieve general information about the object:"
   ],
   "id": "a034385fda6ba929"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(sars)",
   "id": "f944617123c96808"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(sars.title)",
   "id": "fd06f9199b362ac9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(len(sars.genes))",
   "id": "e70b30c93543fac2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(len(sars.coldata))",
   "id": "f4c45c47147fa06c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "It is straight-forward to filter genes:"
   ],
   "id": "41a208107c856889"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Anpassen\n",
    "from Py.processing import filter_genes\n",
    "sars = filter_genes(sars)\n",
    "print(len(sars.genes))"
   ],
   "id": "a5c258896f7903ad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "By default genes are retained if they have 100 read counts in at least half of the samples (or cells). There are many options how to filter by genes (note that `filter_genes` returns a new grandPy object, and below we directly call `len()` on this new object to check how many genes are retained by filtering):",
   "id": "11c51492e97a99ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(f\"Genes with at least 1000 read counts in half of the columns: {len((filter_genes(sars, min_expression=1000, return_genes=True)))}\")",
   "id": "c3ae55c80582c888"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(f\"Genes with at least 1000 read counts in half of the columns (retain two genes that are otherwise filtered): {len((filter_genes(sars, min_expression=1000, keep=[\"ATF3\", \"ZC3H12A\"], return_genes=True)))}\")",
   "id": "734d5c178c26edea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(f\"Keep only these two genes: {len((filter_genes(sars, use=[\"ATF3\", \"ZC3H12A\"],return_genes=True)))}\")",
   "id": "36dac79c30658f9d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "sars = sars.normalize_tpm()\n",
    "print(\"Genes with at least 10 TPM in half of the columns:\", len(sars.filter_genes(mode_slot=\"tpm\", min_expression=10, min_columns=sars.coldata.shape[0]/2, return_genes=True)))\n"
   ],
   "id": "ba7f861621793ee6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "`filter_genes` essentially removes rows from the data slots. It is also possible to remove columns (i.e. samples or cells). See this example:",
   "id": "dc72744a97cc7912"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "mock = sars[:, sars.coldata[\"Condition\"] == \"Mock\"]\n",
    "print(mock)"
   ],
   "id": "cf753ff084b9f349"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The new grandPy object now only has 6 columns. The `columns`parameter to subset must be a logical vector, and you can use the names of the column metadata table (see below) as variables (i.e. the parameter here is a logical vector with all samples being TRUE where the `Condition` column is equal to \"Mock\".\n",
    "\n",
    "A closely related function is `split`, which returns a list of several grandPy objects, each composed of samples having the same `Condition`.</span>"
   ],
   "id": "4fcd53d5f03348c6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "object1, object2 = sars.split(by=\"Condition\")\n",
    "print(object1, \"\\n\", object2)"
   ],
   "id": "911efd3c493104ac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(object1.columns, \"\\n\", object2.columns)",
   "id": "2807647c00691681"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The inverse of `split` is `merge`:",
   "id": "e9beb34bb8a3e5b1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(object1.merge(object2, axis=0))",
   "id": "920f4df46ad677ad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "`concat` can also be used, see below:",
   "id": "bffaef43a3474303"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# TODO: fix imports ... next sprint\n",
    "# import grandpy as gp zu beginn von der file\n",
    "# print(gp.concat([object1, object2]))"
   ],
   "id": "d171f238c282ff5e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Note that we merged such that now we have first the SARS samples and then the Mock samples. We can also do it another way (see below):",
   "id": "b2eb1a7e8c7010df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "object1 = sars[:,sars.coldata[\"Condition\"] == \"Mock\"]\n",
    "object2 = sars[:,sars.coldata[\"Condition\"] == \"SARS\"]\n",
    "\n",
    "print(object1.columns, \"\\n\", object2.columns)"
   ],
   "id": "b7b664dbb19919bf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Gene metadata\n",
    "\n",
    "Here we see how to work with metadata for genes. The gene metadata essentially is a table that can be retrieved using the `gene_info` function:"
   ],
   "id": "de1582d6119b6a9a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(sars.gene_info.head(10))\n",
    "\n",
    "# Ausgabe eig von 27 - 47 und nach Länge sortiert?"
   ],
   "id": "c5dea71324a82ec2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Each gene has associated gene ids and symbols. Gene ids and symbols as well as the transcript length are part of GRAND-SLAM output. The `TRype` column is inferred automatically (see below).\n",
    "\n",
    "Genes can be identified with the `genes` & `get_genes` functions:"
   ],
   "id": "45ea7a145a41403d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(sars.genes[:20])",
   "id": "16c217314b09cef0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(sars.get_genes(get_gene_symbols=False)[:20])",
   "id": "6f679e6a33464d67"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(sars.get_genes(genes=[\"MYC\", \"ORF1ab\"],get_gene_symbols=False)[:20])",
   "id": "6ba9997d2ea33e0d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(sars.get_genes(genes=\"YC\", regex=True))",
   "id": "1023950e8f139c4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "During reading the data into Python using `read_grand`, the `Type` column is inferred using the `classify_genes` function. By default, this will recognize mitochondrial genes (MT prefix of the gene symbol), ERCC spike-ins, and Ensembl gene identifiers (which it will call \"cellular\"). Here we also have the viral genes, which are not properly recognized:",
   "id": "17c20054338b45b8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(pd.DataFrame(sars.gene_info[\"Type\"].value_counts()).T)",
   "id": "6dc1928bef5298e1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If you want to define your own types, you can do this easily by specifying the `classify_genes` parameter when read in your data:",
   "id": "13f9fbac7681e756"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "viral_genes = ['ORF3a','E','M','ORF6','ORF7a','ORF7b','ORF8','N','ORF10','ORF1ab','S']\n",
    "sars = read_grand(\"../data/sars.tsv\", design=(\"Condition\", \"dur.4sU\", \"Replicate\"), classification_genes=viral_genes, classification_genes_label=\"viral\")\n",
    "\n",
    "print(pd.DataFrame(sars.gene_info[\"Type\"].value_counts()).T)"
   ],
   "id": "3b06fbcbe64ba0f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Note that each parameter to `classify_genes` must be named (`viral`) and must be a function that takes the gene metadata table and returns a logical vector.\n",
    "\n",
    "The `classify_genes` function has one additional important parameter, which defines how \"Unknown\" types are supposed to be called. For this data set, a similar behavior as above can be accomplished by:"
   ],
   "id": "fd8312f54d7054eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "sars = read_grand(\"../data/sars.tsv\", design=(\"Condition\", \"dur.4sU\", \"Replicate\"), classify_genes_func=lambda df: classify_genes(df, name_unknown=\"viral\"))\n",
    "\n",
    "print(pd.DataFrame(sars.gene_info[\"Type\"].value_counts()).T)"
   ],
   "id": "2fa355cc51561579"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "It is also straight-forward to add additional gene metadata:",
   "id": "f5f7e8a478e9c4b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "sars = sars.with_gene_info(\"length.category\", pd.cut(\n",
    "    sars.gene_info[\"Length\"],\n",
    "    bins=[0, 2000, 5000, float(\"inf\")],\n",
    "    labels=[\"Short\", \"Medium\", \"Long\"]\n",
    "))\n",
    "\n",
    "print(pd.DataFrame(sars.gene_info[\"length.category\"].value_counts()).T)\n",
    "\n",
    "# die Reihenfolge ist nicht perfekt"
   ],
   "id": "8cd8b24b09f4456b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Column Metadata\n",
    "\n",
    "Samples for bulk experiments and cells in single cell experiments are in grandR jointly called \"columns\". The metadata for columns is a table that describes the experimental design we specified when reading in data in grandPy. It can be accessed via the `coldata` function. We can also see that the duration of 4sU has been interpreted and converted to a numeric value (compare \"dur.4sU\" with \"dur.4sU.original\")."
   ],
   "id": "c5487df1c464774a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(sars.coldata)",
   "id": "b49251b11fd80925"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Additional semantics can also be defined. This is done using the function `apply_design_semantics`, which creates a dictionary for the attribute `.attrs[“_semantics”]` in the `coldata` DataFrame. This dictionary is used to interpret design columns (e.g. time, concentration). The function `apply_design_semantics` is called automatically in `build_coldata()`.\n",
    "\n",
    "An important component here is that certain column contents (e.g. time specifications such as '5h' or '30min') can be converted into numerical values. There is already a predefined function `parse_time_string` in `grandPy` for this purpose:"
   ],
   "id": "4f5c8a4130a69ebe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(semantics_time([\"5h\", \"30min\", \"no4sU\"], \"Test\"))",
   "id": "f20c4b19998b4df1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can easily define our own function like this:",
   "id": "22bb465689632c7a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def my_semantics_time(values, name):\n",
    "    df = pd.DataFrame({name: values})\n",
    "    df[name] = df[name].map(parse_time_string)\n",
    "    h = df[name] + 3\n",
    "    def fmt(x):\n",
    "        return f\"{int(x) if x.is_integer() else x}hpi\"\n",
    "    df[\"hpi\"] = h.map(fmt)\n",
    "    df.index = range(1, len(df) + 1)\n",
    "    return df\n",
    "\n",
    "print(my_semantics_time([\"5h\", \"30min\", \"no4sU\"], \"Test\"))"
   ],
   "id": "5cafd9690cdd670"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<span style=\"color:red\"> Here, it is important to mention that at 3h post infection, 4sU was added to the cells for 1, 2, 3 or 4h. The two no4sU samples are also 3h post infection. This function can now be used as `semantics`parameter for `read_grand` like this:</span>",
   "id": "1b56f1867f9d2973"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# # ???\n",
    "#\n",
    "# sars.meta <- ReadGRAND(system.file(\"extdata\", \"sars.tsv.gz\", package = \"grandR\"),\n",
    "#                    design=function(names)\n",
    "#                      MakeColdata(names,\n",
    "#                                  c(\"Cell\",Design$dur.4sU,Design$Replicate),\n",
    "#                                  semantics=DesignSemantics(duration.4sU=my.semantics.time)\n",
    "#                                  ),\n",
    "#                  verbose=TRUE)"
   ],
   "id": "5940caeeaf95ffef"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As mentioned above, it is in most cases easier to add additional metadata after loading.The infection time point can also be added by:",
   "id": "8ad1e6efcd16dab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "hpi_series = sars.coldata[\"duration.4sU\"].apply(lambda x: f\"{x + 3}hpi\")\n",
    "sars = sars.with_coldata(\"hpi\", hpi_series)\n",
    "print(sars.coldata)\n"
   ],
   "id": "43fa9672b7e775df"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<span style=\"color:red\">There are also some build-in grandPy functions that add metadata,such as `compute_expression_percentage`: </span>",
   "id": "28ad18f1dd595d1d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# fehlt in processing.py\n",
    "\n",
    "# sars <- ComputeExpressionPercentage(sars,name = \"viral_percentage\",\n",
    "#                                     genes = GeneInfo(sars,\"Type\")==\"viral\")\n",
    "# ggplot(Coldata(sars),aes(Name,viral_percentage))+\n",
    "#   geom_bar(stat=\"identity\")+\n",
    "#   RotatateAxisLabels()+\n",
    "#   xlab(NULL)\n",
    "\n",
    "# R-code"
   ],
   "id": "636efa9918cd4797"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Interestingly the 4sU-naive sample shows more viral gene expression, suggesting that 4sU had an effect on viral gene expression.\n",
    "\n",
    "Since this is such an important control, there is also a specialized plotting built into grandR for that:"
   ],
   "id": "520aba3438e3aa97"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# PlotTypeDistribution(sars,relative = TRUE)\n",
    "\n",
    "# plot_type_distribution fehlt noch in plot.py"
   ],
   "id": "28598136c3ee1884"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "There is a column in the `coldata` metadata table that has a special meaning: `Condition`. It is used by many functions as a default, e.g. to plot colors in the PCA or to model kinetics per conditions. It can be accessed by its own function:",
   "id": "b2781f9967b3d6d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "sars.condition # Levels ausgabe?",
   "id": "63bb649b2b832ff5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "and it can be set either directly:",
   "id": "77ad7585081971d7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "sars = sars.with_coldata(\"saved\", sars.condition)\n",
    "new_conditions = [\"control\"] * 6 + [\"infected\"] * 6\n",
    "sars = sars.with_condition(new_conditions)\n",
    "print(sars.coldata)\n"
   ],
   "id": "89ffefbcb21af659"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "or from one or several columns of the metadata (here this is not really reasonable, but there are situations where combining more than one metadata column makes sense):",
   "id": "77e51de701513b5b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Condition(sars)<-c(\"saved\",\"Replicate\")   # set it by combining to other columns from the Coldata\n",
    "# Condition(sars)"
   ],
   "id": "330e3645d80966b3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Condition(sars)<-\"saved\"                  # set it to one other column from the Coldata\n",
    "# Condition(sars)"
   ],
   "id": "34ed58a77b07115f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
